{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from nuscenes.utils.data_io import load_bin_file\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import glob\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adperf_utils.perturb_utils import PerturbType as PT\n",
    "from adperf_utils.perturb_utils import perturb_center_y\n",
    "from adperf_utils.perturb_utils import add_noise, add_obs\n",
    "from adperf_utils.perturb_utils import PT_LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nuscenes(file):\n",
    "    return np.fromfile(file, dtype=np.float32).reshape((-1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc = NuScenes(version='v1.0-mini', dataroot='data/nuscenes', verbose=True)\n",
    "corruption_folder = pathlib.Path('data/corruptions')\n",
    "if not corruption_folder.exists():\n",
    "    corruption_folder.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "root_path = pathlib.Path('data/nuscenes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose from ['noise_left', 'noise_right', 'obs_left', 'obs_right', 'center_y']\n",
    "chosen_per_type = 'noise_left'\n",
    "# choose from [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "chosen_noise_level = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PCDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_not_exist = []\n",
    "num_obs_pts = []\n",
    "saving_to = ''\n",
    "\n",
    "data_types = ['lidarseg', 'panoptic']\n",
    "dataset = None\n",
    "chosen_type = 'panoptic'\n",
    "\n",
    "assert chosen_type in data_types\n",
    "\n",
    "if chosen_type == 'lidarseg':\n",
    "    dataset = nusc.lidarseg\n",
    "elif chosen_type == 'panoptic':\n",
    "    dataset = nusc.panoptic\n",
    "\n",
    "\n",
    "for frame in dataset:\n",
    "    # get obstacle info\n",
    "    file_path = root_path / frame['filename']\n",
    "    if not os.path.exists(file_path):\n",
    "        path_not_exist.append(file_path)    \n",
    "    label_array = load_bin_file(file_path, chosen_type)\n",
    "    # masking code for filtering\n",
    "    if chosen_type == 'lidarseg':\n",
    "        label_array_simple = label_array\n",
    "    elif chosen_type == 'panoptic':\n",
    "        label_array_simple = label_array // 1000\n",
    "\n",
    "    # filter vehicles\n",
    "    mask = ((label_array_simple >= 1) & (label_array_simple <= 8)) | ((label_array_simple >= 14) & (label_array_simple <= 23))\n",
    "    \n",
    "    # get lidar file\n",
    "    sample_data_token = frame['sample_data_token']\n",
    "    sample_data_metadata = nusc.get('sample_data', sample_data_token)\n",
    "    lidar_filename = sample_data_metadata['filename']\n",
    "    lidar_file_path = root_path / lidar_filename\n",
    "    if not os.path.exists(lidar_file_path):\n",
    "        path_not_exist.append(lidar_file_path)\n",
    "\n",
    "    # filter points\n",
    "    pcd_scan = read_nuscenes(lidar_file_path)\n",
    "    points_in_obs = pcd_scan[mask]\n",
    "    num_obs_pts.append(len(points_in_obs))\n",
    "\n",
    "\n",
    "    # extract labels for obstacle points\n",
    "    label_array_in_obs = label_array[mask]\n",
    "    assert len(points_in_obs) == len(label_array_in_obs)\n",
    "\n",
    "    # add labels as a new column in pcd\n",
    "    label_array_in_obs = np.reshape(label_array_in_obs, (len(label_array_in_obs), 1))\n",
    "    points_in_obs_w_labels = np.hstack((points_in_obs, label_array_in_obs))\n",
    "\n",
    "    # verify correctness\n",
    "    for idx in range(len(points_in_obs)):\n",
    "        if points_in_obs[idx][0] == points_in_obs_w_labels[idx][0] and points_in_obs[idx][1] == points_in_obs_w_labels[idx][1] and \\\n",
    "           points_in_obs[idx][2] == points_in_obs_w_labels[idx][2] and points_in_obs[idx][3] == points_in_obs_w_labels[idx][3] and \\\n",
    "           points_in_obs[idx][4] == points_in_obs_w_labels[idx][4] and label_array_in_obs[idx][0] == points_in_obs_w_labels[idx][5]:\n",
    "            continue\n",
    "        else:\n",
    "            print('Incorrect labels')\n",
    "            print(idx, points_in_obs[idx], label_array_in_obs[idx], points_in_obs_w_labels[idx])\n",
    "\n",
    "    # modify PCD\n",
    "    per_type = PT_LOOKUP[chosen_per_type]\n",
    "   \n",
    "    if not isinstance(per_type, PT):\n",
    "        print('Invalid per type')\n",
    "        break\n",
    "\n",
    "    # modifications\n",
    "    if per_type == PT.NOISE_LEFT or per_type == PT.NOISE_RIGHT:\n",
    "        curr_corr_pcds_folder_path = corruption_folder / 'pcds' / f'{per_type.name.lower()}_{round(chosen_noise_level * 10)}'\n",
    "        saving_to = curr_corr_pcds_folder_path\n",
    "        corr_arr = add_noise(points_in_obs_w_labels, chosen_noise_level, per_type)\n",
    "        new_pcd_scan = np.concatenate((pcd_scan, corr_arr[:, :5]), axis=0)\n",
    "    elif per_type == PT.OBS_LEFT or per_type == PT.OBS_RIGHT:\n",
    "        chosen_noise_level = 3\n",
    "        curr_corr_pcds_folder_path = corruption_folder / 'pcds' / f'{per_type.name.lower()}_{round(chosen_noise_level * 10)}'\n",
    "        saving_to = curr_corr_pcds_folder_path\n",
    "        corr_arr = add_obs(points_in_obs, chosen_noise_level, per_type)\n",
    "        new_pcd_scan = np.concatenate((pcd_scan, corr_arr), axis=0)\n",
    "    elif per_type == PT.CENTER_Y:\n",
    "        curr_corr_pcds_folder_path = corruption_folder / 'pcds' / f'{per_type.name.lower()}_{round(chosen_noise_level * 10)}'\n",
    "        saving_to = curr_corr_pcds_folder_path\n",
    "        corr_arr = perturb_center_y(points_in_obs_w_labels, chosen_noise_level)\n",
    "        # remove current obstacles from pcd\n",
    "        non_obs_mask = ~mask\n",
    "        remaining_points = pcd_scan[non_obs_mask]\n",
    "        # add new obstacles to pcd (without labels)\n",
    "        new_pcd_scan = np.concatenate((remaining_points, corr_arr[:, :5]), axis=0)\n",
    "    else:\n",
    "        print(f'Invalid perturbation {per_type}')\n",
    "\n",
    "    # write new pcd with modifications to file\n",
    "    if not curr_corr_pcds_folder_path.exists():\n",
    "        curr_corr_pcds_folder_path.mkdir(parents=True, exist_ok=False)\n",
    "    # new_pcd_scan = np.concatenate((pcd_scan, corr_arr), axis=0)\n",
    "    new_pcd_scan.astype(np.float32).tofile(curr_corr_pcds_folder_path / lidar_file_path.name)\n",
    "\n",
    "# print('Summary')\n",
    "# print(f'LIDAR_TOP not exist: {path_not_exist}!')\n",
    "# print(f'Num pts in obs: {num_obs_pts}')\n",
    "with open('trajectory_modification.txt', 'w') as fd:\n",
    "    fd.write(f'{chosen_per_type},{chosen_noise_level}')\n",
    "\n",
    "print(f'Saved PCD to {saving_to}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
